# -*- coding: utf-8 -*-
from typing import List, Dict, Any, Optional, Tuple
import csv
import os
import re
import importlib.util

import numpy as np
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
from matplotlib.ticker import MaxNLocator
import parasail
from collections import defaultdict, OrderedDict


from .utils import BLANK_IDX, ID2BASE, BASE2ID


_SPLIT_CIGAR = re.compile(r"(?P<len>\d+)(?P<op>\D+)")


def koi_beam_search_decode(
    logits_tbc: torch.Tensor,
    beam_width: int = 32,
    beam_cut: float = 100.0,
    scale: float = 1.0,
    offset: float = 0.0,
    blank_score: float = 2.0,
    reverse: bool = False,
    input_lengths: Optional[torch.Tensor] = None,
) -> List[List[int]]:
    try:
        from koi.decode import beam_search, to_str  # type: ignore
    except Exception as exc:
        raise ImportError(
            "Koi beam_search decoder requested but ont-koi is not installed. "
            "Install ont-koi and ensure it matches your PyTorch/CUDA version."
        ) from exc

    if input_lengths is None:
        lengths = [logits_tbc.shape[0]] * logits_tbc.shape[1]
    else:
        lengths = [min(int(x), logits_tbc.shape[0]) for x in input_lengths.cpu().tolist()]
    decoded: List[List[int]] = []
    for b, length in enumerate(lengths):
        if length <= 0:
            decoded.append([])
            continue
        scores = logits_tbc[:length, b : b + 1, :]
        if scores.is_cuda:
            scores = scores.half()
            scores = scores.transpose(0, 1)
        sequence, _qstring, _moves = beam_search(
            scores,
            beam_width=beam_width,
            beam_cut=beam_cut,
            scale=scale,
            offset=offset,
            blank_score=blank_score,
        )
        if reverse:
            sequence = sequence[::-1]
        seq_str = sequence if isinstance(sequence[0], str) else to_str(sequence[0])
        decoded.append([BASE2ID.get(base, BLANK_IDX) for base in seq_str])
    return decoded



def _ids_to_bases(ids: List[int], drop_blank: bool = True) -> str:
    bases: List[str] = []
    for i in ids:
        if drop_blank and i == BLANK_IDX:
            continue
        base = ID2BASE.get(i, "")
        if base:
            bases.append(base)
    return "".join(bases)

def parasail_to_sam(result, seq):
    """
    Extract reference start and sam compatible cigar string.

    :param result: parasail alignment result.
    :param seq: query sequence.

    :returns: reference start coordinate, cigar string.
    """
    cigstr = result.cigar.decode.decode()
    first = re.search(_SPLIT_CIGAR, cigstr)

    first_count, first_op = first.groups()
    prefix = first.group()
    rstart = result.cigar.beg_ref
    cliplen = result.cigar.beg_query

    clip = '' if cliplen == 0 else '{}S'.format(cliplen)
    if first_op == 'I':
        pre = '{}S'.format(int(first_count) + cliplen)
    elif first_op == 'D':
        pre = clip
        rstart = int(first_count)
    else:
        pre = '{}{}'.format(clip, prefix)

    mid = cigstr[len(prefix):]
    end_clip = len(seq) - result.end_query - 1
    suf = '{}S'.format(end_clip) if end_clip > 0 else ''
    new_cigstr = ''.join((pre, mid, suf))
    return rstart, new_cigstr


def cal_bonito_accuracy(pred_seq, ref_seq, balanced=False, min_coverage=0.0):
    """
    Calculate the accuracy between `ref` and `seq`
    """
    alignment = parasail.sw_trace_striped_32(pred_seq, ref_seq, 8, 4, parasail.dnafull)
    counts = defaultdict(int)

    if len(ref_seq) == 0:
        return 0.0

    q_coverage = len(alignment.traceback.query) / max(len(pred_seq), 1)
    r_coverage = len(alignment.traceback.ref) / max(len(ref_seq), 1)

    if r_coverage < min_coverage:
        return 0.0

    _, cigar = parasail_to_sam(alignment, pred_seq)

    for count, op in re.findall(_SPLIT_CIGAR, cigar):
        counts[op] += int(count)

    if balanced:
        accuracy = (counts['='] - counts['I']) / (counts['='] + counts['X'] + counts['D'])
    else:
        accuracy = counts['='] / (counts['='] + counts['I'] + counts['X'] + counts['D'])
    return accuracy * 100


def batch_bonito_accuracy(
    pred_seqs: List[List[int]],
    ref_seqs: List[List[int]],
    balanced: bool = False,
    min_coverage: float = 0.0,
) -> float:
    """
    Bonito-style accuracy across a batch, averaged by per-read accuracy.
    返回百分比（0-100）。
    """
    if not pred_seqs or not ref_seqs:
        return 0.0
    scores = []
    for p_ids, r_ids in zip(pred_seqs, ref_seqs):
        p_str = _ids_to_bases(p_ids, drop_blank=True)
        r_str = _ids_to_bases(r_ids, drop_blank=True)
        scores.append(cal_bonito_accuracy(p_str, r_str, balanced=balanced, min_coverage=min_coverage))
    return float(np.mean(scores)) if scores else 0.0
    


# ---------------- 曲线绘图 & metrics 保存 ----------------

def plot_curves(
    train_losses: List[float],
    val_losses: List[float],
    val_accs: List[float],
    save_path: Optional[str] = None,
):
    """画 Loss + Accuracy 曲线"""
    max_len = min(len(train_losses), len(val_losses), len(val_accs))
    if max_len == 0:
        print("[plot_curves] Empty metrics.")
        return

    train_losses = train_losses[:max_len]
    val_losses = val_losses[:max_len]
    val_accs = val_accs[:max_len]

    epochs = range(1, max_len + 1)

    fig, ax1 = plt.subplots(figsize=(8, 5))
    fig.suptitle(
        "Training Metrics: Loss & Validation Accuracy",
        fontsize=14,
        fontweight="bold",
    )

    ax1.grid(True, linestyle="--", alpha=0.4, axis="both")

    color_loss_train = "#1f77b4"
    color_loss_val = "#ff7f0e"

    ax1.set_xlabel("Epoch", fontsize=12)
    ax1.set_ylabel("Loss", color=color_loss_train, fontsize=12)

    line1 = ax1.plot(
        epochs,
        train_losses,
        label="Train Loss",
        color=color_loss_train,
        linewidth=2,
    )
    line2 = ax1.plot(
        epochs,
        val_losses,
        label="Val Loss",
        color=color_loss_val,
        linestyle="--",
        linewidth=2,
    )
    ax1.tick_params(axis="y", labelcolor=color_loss_train)

    # PBMA on twin axis
    ax2 = ax1.twinx()
    color_acc = "#2ca02c"
    ax2.set_ylabel("Validation Accuracy", color=color_acc, fontsize=12)
    line3 = ax2.plot(
        epochs,
        val_accs,
        label="Val Acc",
        color=color_acc,
        linestyle=":",
        linewidth=2,
    )
    ax2.tick_params(axis="y", labelcolor=color_acc)

    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))
    ax1.set_xlim(left=1, right=max_len)

    lines = line1 + line2 + line3
    labels = [l.get_label() for l in lines]
    ax1.legend(
        lines,
        labels,
        loc="upper right",
        frameon=True,
        fancybox=True,
        fontsize=9,
    )

    fig.tight_layout(rect=[0, 0.03, 1, 0.95])

    if save_path is not None:
        plt.savefig(save_path, dpi=300)
        print(f"[Plot] Saved training curves to: {save_path}")
    else:
        plt.show()

    plt.close(fig)


def save_metrics_csv(
    train_losses: List[float],
    val_losses: List[float],
    val_accs: List[float],
    csv_path: str,
):
    os.makedirs(os.path.dirname(csv_path), exist_ok=True)
    with open(csv_path, "w", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["epoch", "train_loss", "val_loss", "val_acc"])
        for e, tr, vl, pa in zip(
            range(1, len(train_losses) + 1),
            train_losses,
            val_losses,
            val_accs,
        ):
            writer.writerow([e, tr, vl, pa])
    print(f"[Metrics] Saved to {csv_path}")
